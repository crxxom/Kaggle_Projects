{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c9096fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:38:57.807829Z",
     "iopub.status.busy": "2023-09-11T04:38:57.807356Z",
     "iopub.status.idle": "2023-09-11T04:39:14.834519Z",
     "shell.execute_reply": "2023-09-11T04:39:14.833518Z"
    },
    "papermill": {
     "duration": 17.045937,
     "end_time": "2023-09-11T04:39:14.837251",
     "exception": false,
     "start_time": "2023-09-11T04:38:57.791314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DebertaTokenizer, DebertaModel, DebertaForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "summaries_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n",
    "prompt_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf8f3a",
   "metadata": {
    "papermill": {
     "duration": 0.0098,
     "end_time": "2023-09-11T04:39:14.858284",
     "exception": false,
     "start_time": "2023-09-11T04:39:14.848484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load pretrained DeBERTa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8a2c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:39:14.880828Z",
     "iopub.status.busy": "2023-09-11T04:39:14.880499Z",
     "iopub.status.idle": "2023-09-11T04:39:15.047673Z",
     "shell.execute_reply": "2023-09-11T04:39:15.046697Z"
    },
    "papermill": {
     "duration": 0.181654,
     "end_time": "2023-09-11T04:39:15.050284",
     "exception": false,
     "start_time": "2023-09-11T04:39:14.868630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length,mode=\"train\"):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        text = item['text']\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        if self.mode ==\"train\":\n",
    "            content_label = torch.tensor(item['content'], dtype=torch.float32)\n",
    "            wording_label = torch.tensor(item['wording'], dtype=torch.float32)\n",
    "            return {\n",
    "                'input_ids': inputs['input_ids'].flatten(),\n",
    "                'attention_mask': inputs['attention_mask'].flatten(),\n",
    "                'content_label': content_label,\n",
    "                'wording_label': wording_label\n",
    "            }\n",
    "        elif self.mode==\"test\":\n",
    "            return {\n",
    "                'input_ids': inputs['input_ids'].flatten(),\n",
    "                'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            }\n",
    "      \n",
    "\n",
    "\n",
    "tokenizer = DebertaTokenizer.from_pretrained('/kaggle/input/hugging-face-models-safe-tensors/deberta-base')\n",
    "\n",
    "max_length = 256\n",
    "# train_dataset = CustomDataset(train_data, tokenizer, max_length,mode=\"train\")\n",
    "# val_dataset = CustomDataset(val_data, tokenizer, max_length, mode=\"train\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    attention_mask = [item['attention_mask'] for item in batch]\n",
    "    content_label = [item['content_label'] for item in batch]\n",
    "    wording_label = [item['wording_label'] for item in batch]\n",
    "    \n",
    "    max_length = max(len(ids) for ids in input_ids)\n",
    "    padded_input_ids = torch.zeros((len(input_ids), max_length), dtype=torch.long)\n",
    "    padded_attention_mask = torch.zeros((len(input_ids), max_length), dtype=torch.long)\n",
    "    \n",
    "    for i, (ids, mask) in enumerate(zip(input_ids, attention_mask)):\n",
    "        padding_length = max_length - len(ids)\n",
    "        padded_input_ids[i, :len(ids)] = ids\n",
    "        padded_attention_mask[i, :len(mask)] = mask\n",
    "    \n",
    "    return {\n",
    "        'input_ids': padded_input_ids,\n",
    "        'attention_mask': padded_attention_mask,\n",
    "        'content_label': torch.stack(content_label),\n",
    "        'wording_label': torch.stack(wording_label)\n",
    "    }\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn = collate_fn)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ff9cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:39:15.073437Z",
     "iopub.status.busy": "2023-09-11T04:39:15.073089Z",
     "iopub.status.idle": "2023-09-11T04:39:15.147208Z",
     "shell.execute_reply": "2023-09-11T04:39:15.146250Z"
    },
    "papermill": {
     "duration": 0.087759,
     "end_time": "2023-09-11T04:39:15.149296",
     "exception": false,
     "start_time": "2023-09-11T04:39:15.061537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DeBERTa\n",
    "class DeBERTaForRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeBERTaForRegression, self).__init__()\n",
    "        self.deberta = DebertaForSequenceClassification.from_pretrained('/kaggle/input/hugging-face-models-safe-tensors/deberta-base', num_labels=2)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.logits\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = DeBERTaForRegression().to(device)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26dbfc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:39:15.171925Z",
     "iopub.status.busy": "2023-09-11T04:39:15.171592Z",
     "iopub.status.idle": "2023-09-11T04:39:29.732140Z",
     "shell.execute_reply": "2023-09-11T04:39:29.730905Z"
    },
    "papermill": {
     "duration": 14.575644,
     "end_time": "2023-09-11T04:39:29.735646",
     "exception": false,
     "start_time": "2023-09-11T04:39:15.160002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deberta_model = torch.load('/kaggle/input/deberta-commonlit-pretrained-model/deberta_trained1',map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4a08d",
   "metadata": {
    "papermill": {
     "duration": 0.020248,
     "end_time": "2023-09-11T04:39:29.775756",
     "exception": false,
     "start_time": "2023-09-11T04:39:29.755508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d06ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:39:29.813199Z",
     "iopub.status.busy": "2023-09-11T04:39:29.812662Z",
     "iopub.status.idle": "2023-09-11T04:40:04.847045Z",
     "shell.execute_reply": "2023-09-11T04:40:04.845706Z"
    },
    "papermill": {
     "duration": 35.054205,
     "end_time": "2023-09-11T04:40:04.850274",
     "exception": false,
     "start_time": "2023-09-11T04:39:29.796069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cfe2616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:40:04.876604Z",
     "iopub.status.busy": "2023-09-11T04:40:04.874809Z",
     "iopub.status.idle": "2023-09-11T04:40:09.045555Z",
     "shell.execute_reply": "2023-09-11T04:40:09.044478Z"
    },
    "papermill": {
     "duration": 4.186288,
     "end_time": "2023-09-11T04:40:09.048443",
     "exception": false,
     "start_time": "2023-09-11T04:40:04.862155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efce3a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:40:09.073144Z",
     "iopub.status.busy": "2023-09-11T04:40:09.072474Z",
     "iopub.status.idle": "2023-09-11T04:40:09.113181Z",
     "shell.execute_reply": "2023-09-11T04:40:09.112022Z"
    },
    "papermill": {
     "duration": 0.056229,
     "end_time": "2023-09-11T04:40:09.115918",
     "exception": false,
     "start_time": "2023-09-11T04:40:09.059689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main idea of preprocessor is to capture the relation between prompt and summary as much as possible\n",
    "# since this relationship is neglected in the roberta training model\n",
    "class Preprocess:\n",
    "    def __init__(self, df):\n",
    "        self.spellchecker = SpellChecker() \n",
    "#         self.speller = Speller(lang='en')\n",
    "        self.dataframe = df\n",
    "        self.index = df.index.values\n",
    "    \n",
    "# ================================================================\n",
    "# SUPPORT FUNCTIONS \n",
    "\n",
    "    def remove_punct(self,text):\n",
    "        return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    def remove_stopwords(self,text):\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        # Get the English stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        # Remove stop words\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "        # Join the filtered words back into a sentence\n",
    "        filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "        return filtered_text\n",
    "        \n",
    "    \n",
    "# ================================================================\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# TRANSFORMATION FUNCTIONS\n",
    "\n",
    "    # count of words in summary\n",
    "    def summary_text_count(self,row):\n",
    "        tokenized_text = word_tokenize(row['text'])\n",
    "        return len(tokenized_text)\n",
    "\n",
    "    # word length of summary/word length of prompt\n",
    "    def summary_prompt_length_ratio(self,row):\n",
    "        prompt_length = len(word_tokenize(row['prompt_text']))\n",
    "        if prompt_length == 0:\n",
    "            return 0\n",
    "        return row['summary_text_count'] / prompt_length\n",
    "\n",
    "    def autocorrection(self,row):\n",
    "        return \n",
    "    # unigram overlap (1 gram) between summary and prompt\n",
    "    def unigram_overlap(self,row):\n",
    "        try:\n",
    "            prompt_tokens = word_tokenize(self.remove_stopwords(self.remove_punct(row['prompt_text'])))\n",
    "            summary_tokens = word_tokenize(self.remove_stopwords(self.remove_punct(row['text'])))\n",
    "        except:\n",
    "            prompt_tokens = word_tokenize(self.remove_punct(row['prompt_text']))\n",
    "            summary_tokens = word_tokenize(self.remove_punct(row['text']))\n",
    "            print('Some problem with removing stopwords')\n",
    "        \n",
    "        # Calculate the number of common n-grams\n",
    "        common_ngrams = set(prompt_tokens).intersection(set(summary_tokens))\n",
    "\n",
    "        prompt_ngram_freq = Counter(prompt_tokens)\n",
    "        summary_ngram_freq = Counter(summary_tokens)\n",
    "        unigram_score = 0\n",
    "        for ngram in common_ngrams:\n",
    "            unigram_score += prompt_ngram_freq[ngram] * summary_ngram_freq[ngram] / sum(prompt_ngram_freq.values())\n",
    "        return unigram_score\n",
    "    \n",
    "    # bigram overlap (2 gram) between summary and prompt\n",
    "    def bigram_overlap(self,row):\n",
    "        prompt_tokens = word_tokenize(row['prompt_text'])\n",
    "        summary_tokens = word_tokenize(row['text'])\n",
    "\n",
    "        # Generate n-grams for the original text and summary\n",
    "        prompt_ngrams = list(ngrams(prompt_tokens, 2))\n",
    "        summary_ngrams = list(ngrams(summary_tokens, 2))\n",
    "        # Calculate the number of common n-grams\n",
    "        common_ngrams = set(prompt_ngrams).intersection(set(summary_ngrams))\n",
    "        prompt_ngram_freq = Counter(prompt_ngrams)\n",
    "        summary_ngram_freq = Counter(summary_ngrams)\n",
    "        bigram_score = 0\n",
    "        for ngram in common_ngrams:\n",
    "            bigram_score += prompt_ngram_freq[ngram] * summary_ngram_freq[ngram] / sum(prompt_ngram_freq.values())\n",
    "        return bigram_score\n",
    "    \n",
    "    # trigram overlap (3 gram) between summary and prompt\n",
    "    def trigram_overlap(self,row):\n",
    "        prompt_tokens = word_tokenize(row['prompt_text'])\n",
    "        summary_tokens = word_tokenize(row['text'])\n",
    "\n",
    "        # Generate n-grams for the original text and summary\n",
    "        prompt_ngrams = list(ngrams(prompt_tokens, 3))\n",
    "        summary_ngrams = list(ngrams(summary_tokens, 3))\n",
    "        # Calculate the number of common n-grams\n",
    "        common_ngrams = set(prompt_ngrams).intersection(set(summary_ngrams))\n",
    "\n",
    "        prompt_ngram_freq = Counter(prompt_ngrams)\n",
    "        summary_ngram_freq = Counter(summary_ngrams)\n",
    "        \n",
    "        trigram_score = 0\n",
    "        for ngram in common_ngrams:\n",
    "            trigram_score += prompt_ngram_freq[ngram] * summary_ngram_freq[ngram] / sum(prompt_ngram_freq.values())\n",
    "        return trigram_score\n",
    "    \n",
    "    \n",
    "    # how many unique vocab student used relative to total vocab\n",
    "    def vocab_uniqueness(self, row):\n",
    "        summary_tokens = word_tokenize(self.remove_punct(row['text']))\n",
    "\n",
    "        non_stopword_count = list(summary_tokens)\n",
    "        unique_count = set(summary_tokens)\n",
    "\n",
    "        return len(unique_count) / len(non_stopword_count)\n",
    "    \n",
    "    # return score of NER co occurence between summary and prompt\n",
    "    def NER_co_occurrence(self, row):\n",
    "\n",
    "        # Apply NER to the texts\n",
    "        summary = nlp(row['text'])\n",
    "        prompt = nlp(row['prompt_text'])\n",
    "\n",
    "        # Extract the named entities from each text\n",
    "        summary_entities = [ent.text for ent in summary.ents]\n",
    "        prompt_entities = [ent.text for ent in prompt.ents]\n",
    "\n",
    "        # Find the overlap between the named entities\n",
    "        ent_overlap = set(summary_entities).intersection(set(prompt_entities))\n",
    "\n",
    "        # Count the occurrences of each named entity in the overlap\n",
    "        summary_ent_freq = Counter(summary_entities)\n",
    "        prompt_ent_freq = Counter(prompt_entities)\n",
    "        \n",
    "        ent_score = 0\n",
    "        for ent in ent_overlap:\n",
    "            ent_score += prompt_ent_freq[ent] * summary_ent_freq[ent] / sum(prompt_ent_freq.values())\n",
    "\n",
    "        return ent_score\n",
    "        \n",
    "        \n",
    "    # count the number of misspelled word\n",
    "    def spelling_error(self, row):\n",
    "        wordlist=row['text'].split(' ')\n",
    "        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n",
    "        return amount_miss\n",
    "    \n",
    "    # number of quotes in summary\n",
    "    def quote_count(self, row):\n",
    "        summary = row['text']\n",
    "        text = row['prompt_text']\n",
    "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
    "        if len(quotes_from_summary)>0:\n",
    "            return [quote in text for quote in quotes_from_summary].count(True)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def polarity_subjectivity(self, row):\n",
    "        textblob_result = TextBlob(row['text'])\n",
    "        return pd.Series([textblob_result.sentiment[0], textblob_result.sentiment[1]])\n",
    "    \n",
    "    # create a part of speech counting dataframe \n",
    "    def pos_tagging(self, df):\n",
    "        def count_pos_tags(text):\n",
    "            tokens = word_tokenize(text)\n",
    "            tokens_without_punctuations = [word for word in tokens if word not in string.punctuation]\n",
    "            pos_tags = pos_tag(tokens_without_punctuations)\n",
    "            pos_counts = nltk.FreqDist(tag for word, tag in pos_tags)\n",
    "            return pos_counts\n",
    "\n",
    "        pos_counts_df = df['text'].progress_apply(count_pos_tags).apply(pd.Series)\n",
    "        pos_counts_df = pos_counts_df.fillna(0)\n",
    "        \n",
    "        # include only these tags\n",
    "        pos_included_tags = ['DT', 'JJ', 'NN', 'VBD', 'VB', 'WRB', 'NNS', 'TO', 'CD', 'PRP', 'IN',\n",
    "               'VBP', 'WDT', 'VBZ', 'CC', 'VBG', 'JJR', 'RB', 'NNP', 'JJS', 'VBN',\n",
    "               'EX', 'MD', 'PRP$', 'POS', 'WP', 'RBR', ':']\n",
    "        \n",
    "        # limit columns to only be the ones in the list, and if the columns are are in the original df, fill them all in with zeros\n",
    "        pos_counts_df = pos_counts_df.filter(items=pos_included_tags).reindex(columns=pos_included_tags, fill_value=0)\n",
    "\n",
    "        # Concatenate the new DataFrame with the original one\n",
    "        result_df = pd.concat([df, pos_counts_df], axis=1)\n",
    "        \n",
    "        return result_df\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# Run all the appropriate functions\n",
    "\n",
    "    def run(self):\n",
    "#         step 1: summary_text_count\n",
    "        try:\n",
    "            self.dataframe['summary_text_count'] = self.dataframe.progress_apply(self.summary_text_count, axis=1)\n",
    "        except:\n",
    "            print('Error occur when doing summary text count')\n",
    "        \n",
    "        # step 2: summary_prompt_length_ratio\n",
    "        try:\n",
    "            self.dataframe['summary_prompt_length_ratio'] = self.dataframe.progress_apply(self.summary_prompt_length_ratio, axis=1)\n",
    "        except:\n",
    "            print('Error occur when doing summary_prompt_length_ratio')\n",
    "            \n",
    "        try:\n",
    "            # step 3: ngram_overlap\n",
    "            self.dataframe['unigram_overlap'] = self.dataframe.progress_apply(self.unigram_overlap, axis=1)\n",
    "            self.dataframe['bigram_overlap'] = self.dataframe.progress_apply(self.bigram_overlap, axis=1)\n",
    "            self.dataframe['trigram_overlap'] = self.dataframe.progress_apply(self.trigram_overlap, axis=1)\n",
    "        except:\n",
    "            print('Error occur when doing ngram')\n",
    "        \n",
    "        # step 4: spelling\n",
    "        try:\n",
    "            self.dataframe['spelling_error'] = self.dataframe.progress_apply(self.spelling_error, axis=1)\n",
    "        except:\n",
    "            print('Error occur when doing spelling error')\n",
    "#          # step 5: correct mispelled word\n",
    "#         self.dataframe[\"fixed_summary_text\"] = self.dataframe[\"text\"].progress_apply(\n",
    "#             lambda x: self.speller(x)\n",
    "#         )\n",
    "        \n",
    "        # step 6: quote count\n",
    "        try:\n",
    "            self.dataframe['quote_count'] = self.dataframe.progress_apply(self.quote_count, axis=1)\n",
    "        except:\n",
    "            print('Error occur when doing quote count')\n",
    "            \n",
    "        # step 7: vocab_uniqueness\n",
    "        try:\n",
    "            self.dataframe['vocab_uniqueness'] = self.dataframe.progress_apply(self.vocab_uniqueness, axis=1)\n",
    "        except:\n",
    "            print('Error occur when doing vocab uniqueness')\n",
    "#         # step 7: NER_co_occurrence\n",
    "#         self.dataframe['NER_co_occurrence'] = self.dataframe.progress_apply(self.NER_co_occurrence, axis=1)\n",
    "        \n",
    "        # step 8: polarity and subjectivity\n",
    "        try:\n",
    "            self.dataframe[['polarity', 'subjectivity']] = self.dataframe.progress_apply(self.polarity_subjectivity, axis=1)\n",
    "        except:\n",
    "            print('Error occur when doing polarity')\n",
    "            \n",
    "        # step 9: pos_tagging concat\n",
    "        try:\n",
    "            self.dataframe = self.pos_tagging(self.dataframe)\n",
    "        except:\n",
    "            print('Error occur when doing pos tagging')\n",
    "        \n",
    "#         # step 10: extract/drop necessary features\n",
    "#         self.dataframe.drop(['student_id','prompt_id', 'text', 'prompt_question', 'prompt_title', 'prompt_text'], axis=1, inplace=True)\n",
    "        \n",
    "#         # step 11: standard scaler\n",
    "#         scaler = StandardScaler()\n",
    "#         scaler.fit(self.dataframe)\n",
    "#         scaled_data = scaler.transform(self.dataframe)\n",
    "#         scaled_df = pd.DataFrame(scaled_data, columns=self.dataframe.columns, index=self.index)\n",
    "        \n",
    "        return self.dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e71b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:40:09.140191Z",
     "iopub.status.busy": "2023-09-11T04:40:09.139860Z",
     "iopub.status.idle": "2023-09-11T04:40:10.038686Z",
     "shell.execute_reply": "2023-09-11T04:40:10.037508Z"
    },
    "papermill": {
     "duration": 0.914356,
     "end_time": "2023-09-11T04:40:10.041721",
     "exception": false,
     "start_time": "2023-09-11T04:40:09.127365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/commonlit-datasets/train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035627d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:40:10.068299Z",
     "iopub.status.busy": "2023-09-11T04:40:10.067903Z",
     "iopub.status.idle": "2023-09-11T04:40:10.089108Z",
     "shell.execute_reply": "2023-09-11T04:40:10.087996Z"
    },
    "papermill": {
     "duration": 0.037738,
     "end_time": "2023-09-11T04:40:10.091748",
     "exception": false,
     "start_time": "2023-09-11T04:40:10.054010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop([\"Unnamed: 0\", \"fixed_summary_text\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7cafc85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:40:10.117137Z",
     "iopub.status.busy": "2023-09-11T04:40:10.116774Z",
     "iopub.status.idle": "2023-09-11T04:40:10.164363Z",
     "shell.execute_reply": "2023-09-11T04:40:10.162903Z"
    },
    "papermill": {
     "duration": 0.064417,
     "end_time": "2023-09-11T04:40:10.168293",
     "exception": false,
     "start_time": "2023-09-11T04:40:10.103876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>summary_text_count</th>\n",
       "      <th>summary_prompt_length_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>JJS</th>\n",
       "      <th>VBN</th>\n",
       "      <th>EX</th>\n",
       "      <th>MD</th>\n",
       "      <th>PRP$</th>\n",
       "      <th>POS</th>\n",
       "      <th>WP</th>\n",
       "      <th>RBR</th>\n",
       "      <th>:</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>59</td>\n",
       "      <td>0.084406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "      <td>30</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question prompt_title  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text    student_id  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "\n",
       "                                                text   content   wording  \\\n",
       "0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415   \n",
       "1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058   \n",
       "\n",
       "   summary_text_count  summary_prompt_length_ratio  ...  JJS  VBN   EX   MD  \\\n",
       "0                  59                     0.084406  ...  0.0  1.0  0.0  3.0   \n",
       "1                  30                     0.042918  ...  0.0  1.0  0.0  0.0   \n",
       "\n",
       "   PRP$  POS   WP  RBR    :  fold  \n",
       "0   0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1   0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[2 rows x 47 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "gkf = GroupKFold(n_splits=4)\n",
    "\n",
    "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
    "    train.loc[val_index, \"fold\"] = i\n",
    "\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1859cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:40:10.195904Z",
     "iopub.status.busy": "2023-09-11T04:40:10.195535Z",
     "iopub.status.idle": "2023-09-11T04:43:22.747505Z",
     "shell.execute_reply": "2023-09-11T04:43:22.746207Z"
    },
    "papermill": {
     "duration": 192.568768,
     "end_time": "2023-09-11T04:43:22.750539",
     "exception": false,
     "start_time": "2023-09-11T04:40:10.181771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train, tokenizer, max_length,mode=\"test\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "deberta_model.eval()\n",
    "train_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = deberta_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        content_pred, wording_pred = outputs[0].tolist()\n",
    "        student_id = train.iloc[len(train_predictions)]['student_id']\n",
    "        train_predictions.append([student_id, content_pred, wording_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94aec743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:43:22.777047Z",
     "iopub.status.busy": "2023-09-11T04:43:22.776707Z",
     "iopub.status.idle": "2023-09-11T04:43:22.786273Z",
     "shell.execute_reply": "2023-09-11T04:43:22.784402Z"
    },
    "papermill": {
     "duration": 0.024625,
     "end_time": "2023-09-11T04:43:22.788484",
     "exception": false,
     "start_time": "2023-09-11T04:43:22.763859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pred_df = pd.DataFrame(train_predictions, columns=['student_id','pred_content','pred_wording'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7be233c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:43:22.812688Z",
     "iopub.status.busy": "2023-09-11T04:43:22.812340Z",
     "iopub.status.idle": "2023-09-11T04:43:22.818694Z",
     "shell.execute_reply": "2023-09-11T04:43:22.817584Z"
    },
    "papermill": {
     "duration": 0.021406,
     "end_time": "2023-09-11T04:43:22.821107",
     "exception": false,
     "start_time": "2023-09-11T04:43:22.799701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['pred_content'] = train_pred_df['pred_content']\n",
    "train['pred_wording'] = train_pred_df['pred_wording']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df992e92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:43:22.846098Z",
     "iopub.status.busy": "2023-09-11T04:43:22.845480Z",
     "iopub.status.idle": "2023-09-11T04:43:22.851429Z",
     "shell.execute_reply": "2023-09-11T04:43:22.850501Z"
    },
    "papermill": {
     "duration": 0.021023,
     "end_time": "2023-09-11T04:43:22.853757",
     "exception": false,
     "start_time": "2023-09-11T04:43:22.832734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = [\"content\", \"wording\"]\n",
    "\n",
    "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\"\n",
    "               ] + targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17c37cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:43:22.878976Z",
     "iopub.status.busy": "2023-09-11T04:43:22.878612Z",
     "iopub.status.idle": "2023-09-11T04:44:36.860274Z",
     "shell.execute_reply": "2023-09-11T04:44:36.859238Z"
    },
    "papermill": {
     "duration": 73.997098,
     "end_time": "2023-09-11T04:44:36.863009",
     "exception": false,
     "start_time": "2023-09-11T04:43:22.865911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1.16257\tvalidation_1-rmse:1.12700\n",
      "[100]\tvalidation_0-rmse:0.47131\tvalidation_1-rmse:0.45867\n",
      "[200]\tvalidation_0-rmse:0.25553\tvalidation_1-rmse:0.24181\n",
      "[300]\tvalidation_0-rmse:0.20294\tvalidation_1-rmse:0.18824\n",
      "[400]\tvalidation_0-rmse:0.19000\tvalidation_1-rmse:0.17700\n",
      "[500]\tvalidation_0-rmse:0.18422\tvalidation_1-rmse:0.17523\n",
      "[600]\tvalidation_0-rmse:0.18091\tvalidation_1-rmse:0.17491\n",
      "[700]\tvalidation_0-rmse:0.17858\tvalidation_1-rmse:0.17477\n",
      "[783]\tvalidation_0-rmse:0.17673\tvalidation_1-rmse:0.17483\n",
      "[0]\tvalidation_0-rmse:1.14043\tvalidation_1-rmse:1.18256\n",
      "[100]\tvalidation_0-rmse:0.45835\tvalidation_1-rmse:0.47873\n",
      "[200]\tvalidation_0-rmse:0.24157\tvalidation_1-rmse:0.26625\n",
      "[300]\tvalidation_0-rmse:0.18830\tvalidation_1-rmse:0.22355\n",
      "[400]\tvalidation_0-rmse:0.17558\tvalidation_1-rmse:0.21714\n",
      "[500]\tvalidation_0-rmse:0.17043\tvalidation_1-rmse:0.21639\n",
      "[565]\tvalidation_0-rmse:0.16848\tvalidation_1-rmse:0.21650\n",
      "[0]\tvalidation_0-rmse:1.15704\tvalidation_1-rmse:1.14026\n",
      "[100]\tvalidation_0-rmse:0.46708\tvalidation_1-rmse:0.45349\n",
      "[200]\tvalidation_0-rmse:0.24944\tvalidation_1-rmse:0.24198\n",
      "[300]\tvalidation_0-rmse:0.19574\tvalidation_1-rmse:0.19844\n",
      "[400]\tvalidation_0-rmse:0.18245\tvalidation_1-rmse:0.19317\n",
      "[500]\tvalidation_0-rmse:0.17697\tvalidation_1-rmse:0.19391\n",
      "[507]\tvalidation_0-rmse:0.17669\tvalidation_1-rmse:0.19399\n",
      "[0]\tvalidation_0-rmse:1.15000\tvalidation_1-rmse:1.16577\n",
      "[100]\tvalidation_0-rmse:0.46242\tvalidation_1-rmse:0.48859\n",
      "[200]\tvalidation_0-rmse:0.24498\tvalidation_1-rmse:0.28471\n",
      "[300]\tvalidation_0-rmse:0.19251\tvalidation_1-rmse:0.23613\n",
      "[400]\tvalidation_0-rmse:0.18055\tvalidation_1-rmse:0.22488\n",
      "[500]\tvalidation_0-rmse:0.17582\tvalidation_1-rmse:0.22301\n",
      "[600]\tvalidation_0-rmse:0.17286\tvalidation_1-rmse:0.22219\n",
      "[700]\tvalidation_0-rmse:0.17084\tvalidation_1-rmse:0.22208\n",
      "[800]\tvalidation_0-rmse:0.16860\tvalidation_1-rmse:0.22191\n",
      "[900]\tvalidation_0-rmse:0.16620\tvalidation_1-rmse:0.22176\n",
      "[999]\tvalidation_0-rmse:0.16419\tvalidation_1-rmse:0.22184\n",
      "[0]\tvalidation_0-rmse:1.14513\tvalidation_1-rmse:1.22305\n",
      "[100]\tvalidation_0-rmse:0.49080\tvalidation_1-rmse:0.51124\n",
      "[200]\tvalidation_0-rmse:0.30320\tvalidation_1-rmse:0.29714\n",
      "[300]\tvalidation_0-rmse:0.26037\tvalidation_1-rmse:0.25143\n",
      "[400]\tvalidation_0-rmse:0.24723\tvalidation_1-rmse:0.24265\n",
      "[500]\tvalidation_0-rmse:0.24015\tvalidation_1-rmse:0.24128\n",
      "[600]\tvalidation_0-rmse:0.23549\tvalidation_1-rmse:0.24097\n",
      "[693]\tvalidation_0-rmse:0.23211\tvalidation_1-rmse:0.24107\n",
      "[0]\tvalidation_0-rmse:1.19378\tvalidation_1-rmse:1.09897\n",
      "[100]\tvalidation_0-rmse:0.49581\tvalidation_1-rmse:0.48730\n",
      "[200]\tvalidation_0-rmse:0.28757\tvalidation_1-rmse:0.32897\n",
      "[300]\tvalidation_0-rmse:0.24031\tvalidation_1-rmse:0.30231\n",
      "[400]\tvalidation_0-rmse:0.22737\tvalidation_1-rmse:0.30127\n",
      "[500]\tvalidation_0-rmse:0.22099\tvalidation_1-rmse:0.29957\n",
      "[600]\tvalidation_0-rmse:0.21744\tvalidation_1-rmse:0.29889\n",
      "[700]\tvalidation_0-rmse:0.21457\tvalidation_1-rmse:0.29871\n",
      "[800]\tvalidation_0-rmse:0.21205\tvalidation_1-rmse:0.29884\n",
      "[838]\tvalidation_0-rmse:0.21119\tvalidation_1-rmse:0.29894\n",
      "[0]\tvalidation_0-rmse:1.14956\tvalidation_1-rmse:1.21433\n",
      "[100]\tvalidation_0-rmse:0.49189\tvalidation_1-rmse:0.49336\n",
      "[200]\tvalidation_0-rmse:0.30249\tvalidation_1-rmse:0.28451\n",
      "[300]\tvalidation_0-rmse:0.26004\tvalidation_1-rmse:0.24392\n",
      "[400]\tvalidation_0-rmse:0.24687\tvalidation_1-rmse:0.23915\n",
      "[500]\tvalidation_0-rmse:0.24059\tvalidation_1-rmse:0.23926\n",
      "[542]\tvalidation_0-rmse:0.23880\tvalidation_1-rmse:0.23956\n",
      "[0]\tvalidation_0-rmse:1.18040\tvalidation_1-rmse:1.09756\n",
      "[100]\tvalidation_0-rmse:0.49471\tvalidation_1-rmse:0.50668\n",
      "[200]\tvalidation_0-rmse:0.29363\tvalidation_1-rmse:0.34359\n",
      "[300]\tvalidation_0-rmse:0.24923\tvalidation_1-rmse:0.31057\n",
      "[400]\tvalidation_0-rmse:0.23682\tvalidation_1-rmse:0.30425\n",
      "[500]\tvalidation_0-rmse:0.23104\tvalidation_1-rmse:0.30425\n",
      "[535]\tvalidation_0-rmse:0.22950\tvalidation_1-rmse:0.30411\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "for target in targets:\n",
    "    models = []\n",
    "    for fold in range(4):\n",
    "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
    "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
    "\n",
    "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        #Build the model\n",
    "        model = xgb.XGBRegressor(base_score=0.5, booster='gbtree',    \n",
    "                           n_estimators=1000,\n",
    "                           early_stopping_rounds=100,\n",
    "                           objective='reg:squarederror',\n",
    "                           max_depth=4,\n",
    "                           learning_rate=0.01,\n",
    "                           alpha=0.5,\n",
    "                           reg_lambda=1.0)\n",
    "        model.fit(X_train_cv, y_train_cv,\n",
    "            eval_set=[(X_train_cv, y_train_cv), (X_eval_cv, y_eval_cv)],\n",
    "            verbose=100)\n",
    "        \n",
    "        models.append(model)\n",
    "    \n",
    "    model_dict[target] = models\n",
    "# After hyperparameter tuning\n",
    "# {'alpha': 0.5,\n",
    "#  'gamma': 0,\n",
    "#  'lambda': 1.0,\n",
    "#  'learning_rate': 0.01,\n",
    "#  'max_depth': 4,\n",
    "#  'n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a11d0210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:44:36.897372Z",
     "iopub.status.busy": "2023-09-11T04:44:36.897018Z",
     "iopub.status.idle": "2023-09-11T04:44:37.089773Z",
     "shell.execute_reply": "2023-09-11T04:44:37.088505Z"
    },
    "papermill": {
     "duration": 0.212682,
     "end_time": "2023-09-11T04:44:37.092200",
     "exception": false,
     "start_time": "2023-09-11T04:44:36.879518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_rmse : 0.19961580966393763\n",
      "wording_rmse : 0.267893433532158\n",
      "mcrmse : 0.23375462159804783\n"
     ]
    }
   ],
   "source": [
    "# cv\n",
    "rmses = []\n",
    "\n",
    "for target in targets:\n",
    "    models = model_dict[target]\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    for fold, model in enumerate(models):\n",
    "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        pred = model.predict(X_eval_cv)\n",
    "\n",
    "        trues.extend(y_eval_cv)\n",
    "        preds.extend(pred)\n",
    "        \n",
    "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "    print(f\"{target}_rmse : {rmse}\")\n",
    "    rmses = rmses + [rmse]\n",
    "\n",
    "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9f03b",
   "metadata": {
    "papermill": {
     "duration": 0.018292,
     "end_time": "2023-09-11T04:44:37.129241",
     "exception": false,
     "start_time": "2023-09-11T04:44:37.110949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870b6b9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:44:37.167873Z",
     "iopub.status.busy": "2023-09-11T04:44:37.167128Z",
     "iopub.status.idle": "2023-09-11T04:44:37.307539Z",
     "shell.execute_reply": "2023-09-11T04:44:37.306516Z"
    },
    "papermill": {
     "duration": 0.162452,
     "end_time": "2023-09-11T04:44:37.309813",
     "exception": false,
     "start_time": "2023-09-11T04:44:37.147361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question prompt_title  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text    student_id  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "\n",
       "                                                text  \n",
       "0  1 element of an ideal tragedy is that it shoul...  \n",
       "1  The three elements of an ideal tragedy are:  H...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\")\n",
    "prompts_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\")\n",
    "\n",
    "summaries_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\")\n",
    "summaries_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\")\n",
    "\n",
    "if len(prompts_test) == 2:\n",
    "    prompts_test = prompts_train.copy()\n",
    "    summaries_test = summaries_train.copy()\n",
    "    summaries_test.drop(['content','wording'],axis=1,inplace=True)\n",
    "\n",
    "test_pretrain = pd.merge(prompts_test, summaries_test, on='prompt_id')\n",
    "test_pretrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f146965c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:44:37.346660Z",
     "iopub.status.busy": "2023-09-11T04:44:37.346118Z",
     "iopub.status.idle": "2023-09-11T04:50:54.844481Z",
     "shell.execute_reply": "2023-09-11T04:50:54.843368Z"
    },
    "papermill": {
     "duration": 377.51942,
     "end_time": "2023-09-11T04:50:54.847128",
     "exception": false,
     "start_time": "2023-09-11T04:44:37.327708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7165/7165 [00:07<00:00, 923.33it/s]\n",
      "100%|██████████| 7165/7165 [01:06<00:00, 107.47it/s]\n",
      "100%|██████████| 7165/7165 [01:24<00:00, 84.76it/s]\n",
      "100%|██████████| 7165/7165 [01:20<00:00, 89.36it/s]\n",
      "100%|██████████| 7165/7165 [01:19<00:00, 89.88it/s]\n",
      "100%|██████████| 7165/7165 [00:01<00:00, 4211.84it/s]\n",
      "100%|██████████| 7165/7165 [00:00<00:00, 44665.95it/s]\n",
      "100%|██████████| 7165/7165 [00:05<00:00, 1319.86it/s]\n",
      "100%|██████████| 7165/7165 [00:08<00:00, 825.59it/s]\n",
      "100%|██████████| 7165/7165 [00:40<00:00, 178.31it/s]\n"
     ]
    }
   ],
   "source": [
    "test = Preprocess(test_pretrain.copy()).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "609a364c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:50:55.503952Z",
     "iopub.status.busy": "2023-09-11T04:50:55.503549Z",
     "iopub.status.idle": "2023-09-11T04:53:58.711860Z",
     "shell.execute_reply": "2023-09-11T04:53:58.710595Z"
    },
    "papermill": {
     "duration": 183.563271,
     "end_time": "2023-09-11T04:53:58.715040",
     "exception": false,
     "start_time": "2023-09-11T04:50:55.151769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test, tokenizer, max_length,mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "deberta_model.eval()\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = deberta_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        content_pred, wording_pred = outputs[0].tolist()\n",
    "        student_id = test.iloc[len(test_predictions)]['student_id']\n",
    "        test_predictions.append([student_id, content_pred, wording_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c2b670a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:53:59.357815Z",
     "iopub.status.busy": "2023-09-11T04:53:59.356876Z",
     "iopub.status.idle": "2023-09-11T04:53:59.366568Z",
     "shell.execute_reply": "2023-09-11T04:53:59.365497Z"
    },
    "papermill": {
     "duration": 0.321558,
     "end_time": "2023-09-11T04:53:59.368735",
     "exception": false,
     "start_time": "2023-09-11T04:53:59.047177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred_df = pd.DataFrame(test_predictions, columns=['student_id','pred_content','pred_wording'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3012d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:53:59.974336Z",
     "iopub.status.busy": "2023-09-11T04:53:59.973953Z",
     "iopub.status.idle": "2023-09-11T04:53:59.980813Z",
     "shell.execute_reply": "2023-09-11T04:53:59.979773Z"
    },
    "papermill": {
     "duration": 0.312353,
     "end_time": "2023-09-11T04:53:59.983120",
     "exception": false,
     "start_time": "2023-09-11T04:53:59.670767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['pred_content'] = test_pred_df['pred_content']\n",
    "test['pred_wording'] = test_pred_df['pred_wording']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f321670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:54:00.642538Z",
     "iopub.status.busy": "2023-09-11T04:54:00.642141Z",
     "iopub.status.idle": "2023-09-11T04:54:00.670722Z",
     "shell.execute_reply": "2023-09-11T04:54:00.669483Z"
    },
    "papermill": {
     "duration": 0.393638,
     "end_time": "2023-09-11T04:54:00.673416",
     "exception": false,
     "start_time": "2023-09-11T04:54:00.279778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_text_count</th>\n",
       "      <th>summary_prompt_length_ratio</th>\n",
       "      <th>unigram_overlap</th>\n",
       "      <th>bigram_overlap</th>\n",
       "      <th>...</th>\n",
       "      <th>VBN</th>\n",
       "      <th>EX</th>\n",
       "      <th>MD</th>\n",
       "      <th>PRP$</th>\n",
       "      <th>POS</th>\n",
       "      <th>WP</th>\n",
       "      <th>RBR</th>\n",
       "      <th>:</th>\n",
       "      <th>pred_content</th>\n",
       "      <th>pred_wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>59</td>\n",
       "      <td>0.084406</td>\n",
       "      <td>0.111913</td>\n",
       "      <td>0.030086</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257776</td>\n",
       "      <td>-0.041970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.108060</td>\n",
       "      <td>-0.276407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question prompt_title  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text    student_id  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "\n",
       "                                                text  summary_text_count  \\\n",
       "0  1 element of an ideal tragedy is that it shoul...                  59   \n",
       "1  The three elements of an ideal tragedy are:  H...                  30   \n",
       "\n",
       "   summary_prompt_length_ratio  unigram_overlap  bigram_overlap  ...  VBN  \\\n",
       "0                     0.084406         0.111913        0.030086  ...  1.0   \n",
       "1                     0.042918         0.046931        0.007163  ...  1.0   \n",
       "\n",
       "    EX   MD  PRP$  POS   WP  RBR    :  pred_content  pred_wording  \n",
       "0  0.0  3.0   0.0  0.0  0.0  0.0  0.0      0.257776     -0.041970  \n",
       "1  0.0  0.0   0.0  0.0  0.0  0.0  0.0     -1.108060     -0.276407  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e9e67cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:54:01.352639Z",
     "iopub.status.busy": "2023-09-11T04:54:01.352222Z",
     "iopub.status.idle": "2023-09-11T04:54:01.357358Z",
     "shell.execute_reply": "2023-09-11T04:54:01.356364Z"
    },
    "papermill": {
     "duration": 0.367107,
     "end_time": "2023-09-11T04:54:01.359412",
     "exception": false,
     "start_time": "2023-09-11T04:54:00.992305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_columns = [\"student_id\", \"prompt_id\", \"text\",\n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\"\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e776dccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:54:01.970730Z",
     "iopub.status.busy": "2023-09-11T04:54:01.969951Z",
     "iopub.status.idle": "2023-09-11T04:54:02.501048Z",
     "shell.execute_reply": "2023-09-11T04:54:02.499951Z"
    },
    "papermill": {
     "duration": 0.837856,
     "end_time": "2023-09-11T04:54:02.503884",
     "exception": false,
     "start_time": "2023-09-11T04:54:01.666028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "for target in targets:\n",
    "    models = model_dict[target]\n",
    "    preds = []\n",
    "\n",
    "    for fold, model in enumerate(models):\n",
    "        X_eval_cv = test.drop(columns=drop_columns)\n",
    "\n",
    "        pred = model.predict(X_eval_cv)\n",
    "        preds.append(pred)\n",
    "    \n",
    "    pred_dict[target] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3808cb03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:54:03.118027Z",
     "iopub.status.busy": "2023-09-11T04:54:03.116899Z",
     "iopub.status.idle": "2023-09-11T04:54:03.135937Z",
     "shell.execute_reply": "2023-09-11T04:54:03.134542Z"
    },
    "papermill": {
     "duration": 0.328054,
     "end_time": "2023-09-11T04:54:03.139044",
     "exception": false,
     "start_time": "2023-09-11T04:54:02.810990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    preds = pred_dict[target]\n",
    "    for i, pred in enumerate(preds):\n",
    "        test[f\"{target}_pred_{i}\"] = pred\n",
    "\n",
    "    test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(4)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0403a1b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:54:03.739651Z",
     "iopub.status.busy": "2023-09-11T04:54:03.739229Z",
     "iopub.status.idle": "2023-09-11T04:54:03.765605Z",
     "shell.execute_reply": "2023-09-11T04:54:03.764429Z"
    },
    "papermill": {
     "duration": 0.330234,
     "end_time": "2023-09-11T04:54:03.768334",
     "exception": false,
     "start_time": "2023-09-11T04:54:03.438100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_text_count</th>\n",
       "      <th>summary_prompt_length_ratio</th>\n",
       "      <th>unigram_overlap</th>\n",
       "      <th>bigram_overlap</th>\n",
       "      <th>...</th>\n",
       "      <th>content_pred_0</th>\n",
       "      <th>content_pred_1</th>\n",
       "      <th>content_pred_2</th>\n",
       "      <th>content_pred_3</th>\n",
       "      <th>content</th>\n",
       "      <th>wording_pred_0</th>\n",
       "      <th>wording_pred_1</th>\n",
       "      <th>wording_pred_2</th>\n",
       "      <th>wording_pred_3</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>59</td>\n",
       "      <td>0.084406</td>\n",
       "      <td>0.111913</td>\n",
       "      <td>0.030086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171836</td>\n",
       "      <td>0.192371</td>\n",
       "      <td>0.18753</td>\n",
       "      <td>0.186331</td>\n",
       "      <td>0.184517</td>\n",
       "      <td>-0.063305</td>\n",
       "      <td>-0.114135</td>\n",
       "      <td>-0.112279</td>\n",
       "      <td>-0.051406</td>\n",
       "      <td>-0.085281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.098772</td>\n",
       "      <td>-1.044590</td>\n",
       "      <td>-1.08325</td>\n",
       "      <td>-1.104704</td>\n",
       "      <td>-1.082829</td>\n",
       "      <td>-0.322389</td>\n",
       "      <td>-0.323508</td>\n",
       "      <td>-0.280367</td>\n",
       "      <td>-0.357680</td>\n",
       "      <td>-0.320986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question prompt_title  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text    student_id  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "\n",
       "                                                text  summary_text_count  \\\n",
       "0  1 element of an ideal tragedy is that it shoul...                  59   \n",
       "1  The three elements of an ideal tragedy are:  H...                  30   \n",
       "\n",
       "   summary_prompt_length_ratio  unigram_overlap  bigram_overlap  ...  \\\n",
       "0                     0.084406         0.111913        0.030086  ...   \n",
       "1                     0.042918         0.046931        0.007163  ...   \n",
       "\n",
       "   content_pred_0  content_pred_1  content_pred_2  content_pred_3   content  \\\n",
       "0        0.171836        0.192371         0.18753        0.186331  0.184517   \n",
       "1       -1.098772       -1.044590        -1.08325       -1.104704 -1.082829   \n",
       "\n",
       "   wording_pred_0  wording_pred_1  wording_pred_2  wording_pred_3   wording  \n",
       "0       -0.063305       -0.114135       -0.112279       -0.051406 -0.085281  \n",
       "1       -0.322389       -0.323508       -0.280367       -0.357680 -0.320986  \n",
       "\n",
       "[2 rows x 56 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adab0310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T04:54:04.393671Z",
     "iopub.status.busy": "2023-09-11T04:54:04.393286Z",
     "iopub.status.idle": "2023-09-11T04:54:04.437124Z",
     "shell.execute_reply": "2023-09-11T04:54:04.436029Z"
    },
    "papermill": {
     "duration": 0.352997,
     "end_time": "2023-09-11T04:54:04.439711",
     "exception": false,
     "start_time": "2023-09-11T04:54:04.086714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 914.38061,
   "end_time": "2023-09-11T04:54:08.328727",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-11T04:38:53.948117",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
